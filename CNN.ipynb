{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.genfromtxt('train.csv', delimiter=',')\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000,) (42000, 784)\n"
     ]
    }
   ],
   "source": [
    "# sorting data in Y and X\n",
    "Y = data[0: ,0]\n",
    "X = data[0: ,1: ]\n",
    "print(Y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channel = 1\n",
    "\n",
    "# Define model parameters\n",
    "nb_classes = 10\n",
    "\n",
    "#batch_size to train\n",
    "batch_size = 256\n",
    "\n",
    "# number of output classes\n",
    "nb_classes = 10\n",
    "\n",
    "# number of epochs to train\n",
    "nb_epoch = 150\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters_1 = 20\n",
    "nb_filters_2 = 50\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "\n",
    "# convolution kernel size\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 28, 28, 1) (33600, 10) (8400, 28, 28, 1) (8400, 10)\n"
     ]
    }
   ],
   "source": [
    "# Using correct dimesntions for input data\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# Assigning X_train and X_test as float\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "Y_train = to_categorical(Y_train, nb_classes)\n",
    "Y_test = to_categorical(Y_test, nb_classes)\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing CNN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters_1, kernel_size = (nb_conv, nb_conv), activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(MaxPooling2D(pool_size = (nb_pool, nb_pool), strides = (2, 2)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(nb_filters_2, kernel_size = (nb_conv, nb_conv), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (nb_pool, nb_pool), strides = (2, 2)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 24, 24, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 50)          25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               205056    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 233,196\n",
      "Trainable params: 233,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Optimizer used is Stochastic Gradient Descent with learning rate of 0.01\n",
    "# Loss is calculated using categorical cross entropy\n",
    "opt = SGD(lr = 0.01)\n",
    "ReducedLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_lr=1*10**-7)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ayush Shirsat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 26880 samples, validate on 6720 samples\n",
      "Epoch 1/150\n",
      "26880/26880 [==============================] - 15s 540us/step - loss: 2.2306 - acc: 0.2722 - val_loss: 2.0905 - val_acc: 0.6496\n",
      "Epoch 2/150\n",
      "26880/26880 [==============================] - 14s 537us/step - loss: 1.6736 - acc: 0.5601 - val_loss: 0.9542 - val_acc: 0.8097\n",
      "Epoch 3/150\n",
      "26880/26880 [==============================] - 15s 574us/step - loss: 0.8235 - acc: 0.7510 - val_loss: 0.5090 - val_acc: 0.8595\n",
      "Epoch 4/150\n",
      "26880/26880 [==============================] - 14s 515us/step - loss: 0.5782 - acc: 0.8185 - val_loss: 0.3977 - val_acc: 0.8863\n",
      "Epoch 5/150\n",
      "26880/26880 [==============================] - 15s 543us/step - loss: 0.4770 - acc: 0.8538 - val_loss: 0.3441 - val_acc: 0.9001\n",
      "Epoch 6/150\n",
      "26880/26880 [==============================] - 15s 573us/step - loss: 0.4151 - acc: 0.8718 - val_loss: 0.3034 - val_acc: 0.9137\n",
      "Epoch 7/150\n",
      "26880/26880 [==============================] - 18s 684us/step - loss: 0.3701 - acc: 0.8856 - val_loss: 0.2761 - val_acc: 0.9186\n",
      "Epoch 8/150\n",
      "26880/26880 [==============================] - 17s 649us/step - loss: 0.3343 - acc: 0.8965 - val_loss: 0.2515 - val_acc: 0.9271\n",
      "Epoch 9/150\n",
      "26880/26880 [==============================] - 17s 628us/step - loss: 0.3102 - acc: 0.9054 - val_loss: 0.2325 - val_acc: 0.9327\n",
      "Epoch 10/150\n",
      "26880/26880 [==============================] - 17s 616us/step - loss: 0.2866 - acc: 0.9119 - val_loss: 0.2194 - val_acc: 0.9348\n",
      "Epoch 11/150\n",
      "26880/26880 [==============================] - 16s 584us/step - loss: 0.2700 - acc: 0.9178 - val_loss: 0.2055 - val_acc: 0.9397\n",
      "Epoch 12/150\n",
      "26880/26880 [==============================] - 15s 565us/step - loss: 0.2523 - acc: 0.9241 - val_loss: 0.1938 - val_acc: 0.9427\n",
      "Epoch 13/150\n",
      "26880/26880 [==============================] - 14s 532us/step - loss: 0.2422 - acc: 0.9259 - val_loss: 0.1858 - val_acc: 0.9449\n",
      "Epoch 14/150\n",
      "26880/26880 [==============================] - 15s 566us/step - loss: 0.2293 - acc: 0.9291 - val_loss: 0.1773 - val_acc: 0.9485\n",
      "Epoch 15/150\n",
      "26880/26880 [==============================] - 14s 536us/step - loss: 0.2189 - acc: 0.9321 - val_loss: 0.1683 - val_acc: 0.9494\n",
      "Epoch 16/150\n",
      "26880/26880 [==============================] - 15s 564us/step - loss: 0.2116 - acc: 0.9368 - val_loss: 0.1626 - val_acc: 0.9509\n",
      "Epoch 17/150\n",
      "26880/26880 [==============================] - 15s 554us/step - loss: 0.2004 - acc: 0.9392 - val_loss: 0.1570 - val_acc: 0.9509\n",
      "Epoch 18/150\n",
      "26880/26880 [==============================] - 17s 630us/step - loss: 0.1915 - acc: 0.9413 - val_loss: 0.1515 - val_acc: 0.9549\n",
      "Epoch 19/150\n",
      "26880/26880 [==============================] - 14s 534us/step - loss: 0.1840 - acc: 0.9446 - val_loss: 0.1454 - val_acc: 0.9551\n",
      "Epoch 20/150\n",
      "26880/26880 [==============================] - 16s 586us/step - loss: 0.1799 - acc: 0.9451 - val_loss: 0.1420 - val_acc: 0.9565\n",
      "Epoch 21/150\n",
      "26880/26880 [==============================] - 14s 526us/step - loss: 0.1760 - acc: 0.9468 - val_loss: 0.1364 - val_acc: 0.9583\n",
      "Epoch 22/150\n",
      "26880/26880 [==============================] - 15s 566us/step - loss: 0.1690 - acc: 0.9506 - val_loss: 0.1330 - val_acc: 0.9598\n",
      "Epoch 23/150\n",
      "26880/26880 [==============================] - 16s 588us/step - loss: 0.1662 - acc: 0.9502 - val_loss: 0.1310 - val_acc: 0.9595\n",
      "Epoch 24/150\n",
      "26880/26880 [==============================] - 15s 556us/step - loss: 0.1617 - acc: 0.9500 - val_loss: 0.1264 - val_acc: 0.9609\n",
      "Epoch 25/150\n",
      "26880/26880 [==============================] - 15s 565us/step - loss: 0.1547 - acc: 0.9530 - val_loss: 0.1227 - val_acc: 0.9625\n",
      "Epoch 26/150\n",
      "26880/26880 [==============================] - 15s 557us/step - loss: 0.1527 - acc: 0.9523 - val_loss: 0.1207 - val_acc: 0.9625\n",
      "Epoch 27/150\n",
      "26880/26880 [==============================] - 15s 574us/step - loss: 0.1471 - acc: 0.9550 - val_loss: 0.1176 - val_acc: 0.9621\n",
      "Epoch 28/150\n",
      "26880/26880 [==============================] - 16s 608us/step - loss: 0.1430 - acc: 0.9559 - val_loss: 0.1141 - val_acc: 0.9643\n",
      "Epoch 29/150\n",
      "26880/26880 [==============================] - 15s 559us/step - loss: 0.1420 - acc: 0.9567 - val_loss: 0.1113 - val_acc: 0.9659\n",
      "Epoch 30/150\n",
      "26880/26880 [==============================] - 15s 547us/step - loss: 0.1392 - acc: 0.9567 - val_loss: 0.1092 - val_acc: 0.9673\n",
      "Epoch 31/150\n",
      "26880/26880 [==============================] - 14s 524us/step - loss: 0.1335 - acc: 0.9585 - val_loss: 0.1083 - val_acc: 0.9662\n",
      "Epoch 32/150\n",
      "26880/26880 [==============================] - 14s 506us/step - loss: 0.1331 - acc: 0.9591 - val_loss: 0.1057 - val_acc: 0.9671\n",
      "Epoch 33/150\n",
      "26880/26880 [==============================] - 15s 552us/step - loss: 0.1291 - acc: 0.9604 - val_loss: 0.1032 - val_acc: 0.9676\n",
      "Epoch 34/150\n",
      "26880/26880 [==============================] - 14s 523us/step - loss: 0.1244 - acc: 0.9622 - val_loss: 0.1014 - val_acc: 0.9685\n",
      "Epoch 35/150\n",
      "26880/26880 [==============================] - 14s 525us/step - loss: 0.1238 - acc: 0.9603 - val_loss: 0.1001 - val_acc: 0.9696\n",
      "Epoch 36/150\n",
      "26880/26880 [==============================] - 15s 562us/step - loss: 0.1197 - acc: 0.9629 - val_loss: 0.0995 - val_acc: 0.9688\n",
      "Epoch 37/150\n",
      "26880/26880 [==============================] - 15s 577us/step - loss: 0.1195 - acc: 0.9625 - val_loss: 0.0973 - val_acc: 0.9688\n",
      "Epoch 38/150\n",
      "26880/26880 [==============================] - 16s 607us/step - loss: 0.1201 - acc: 0.9628 - val_loss: 0.0954 - val_acc: 0.9696\n",
      "Epoch 39/150\n",
      "26880/26880 [==============================] - 15s 576us/step - loss: 0.1181 - acc: 0.9632 - val_loss: 0.0941 - val_acc: 0.9704\n",
      "Epoch 40/150\n",
      "26880/26880 [==============================] - 16s 587us/step - loss: 0.1149 - acc: 0.9652 - val_loss: 0.0930 - val_acc: 0.9704\n",
      "Epoch 41/150\n",
      "26880/26880 [==============================] - 16s 605us/step - loss: 0.1119 - acc: 0.9665 - val_loss: 0.0922 - val_acc: 0.9720\n",
      "Epoch 42/150\n",
      "26880/26880 [==============================] - 16s 581us/step - loss: 0.1107 - acc: 0.9650 - val_loss: 0.0896 - val_acc: 0.9722\n",
      "Epoch 43/150\n",
      "26880/26880 [==============================] - 15s 551us/step - loss: 0.1075 - acc: 0.9667 - val_loss: 0.0882 - val_acc: 0.9728\n",
      "Epoch 44/150\n",
      "26880/26880 [==============================] - 16s 593us/step - loss: 0.1064 - acc: 0.9656 - val_loss: 0.0882 - val_acc: 0.9732\n",
      "Epoch 45/150\n",
      "26880/26880 [==============================] - 15s 556us/step - loss: 0.1062 - acc: 0.9673 - val_loss: 0.0862 - val_acc: 0.9728\n",
      "Epoch 46/150\n",
      "26880/26880 [==============================] - 16s 589us/step - loss: 0.1039 - acc: 0.9675 - val_loss: 0.0858 - val_acc: 0.9731\n",
      "Epoch 47/150\n",
      "26880/26880 [==============================] - 16s 582us/step - loss: 0.1022 - acc: 0.9673 - val_loss: 0.0843 - val_acc: 0.9743\n",
      "Epoch 48/150\n",
      "26880/26880 [==============================] - 16s 589us/step - loss: 0.1008 - acc: 0.9677 - val_loss: 0.0863 - val_acc: 0.9731\n",
      "Epoch 49/150\n",
      "26880/26880 [==============================] - 15s 562us/step - loss: 0.1029 - acc: 0.9679 - val_loss: 0.0824 - val_acc: 0.9746\n",
      "Epoch 50/150\n",
      "26880/26880 [==============================] - 16s 591us/step - loss: 0.0987 - acc: 0.9690 - val_loss: 0.0824 - val_acc: 0.9747\n",
      "Epoch 51/150\n",
      "26880/26880 [==============================] - 16s 587us/step - loss: 0.0963 - acc: 0.9698 - val_loss: 0.0800 - val_acc: 0.9756\n",
      "Epoch 52/150\n",
      "26880/26880 [==============================] - 16s 604us/step - loss: 0.0961 - acc: 0.9686 - val_loss: 0.0795 - val_acc: 0.9749\n",
      "Epoch 53/150\n",
      "26880/26880 [==============================] - 17s 616us/step - loss: 0.0937 - acc: 0.9701 - val_loss: 0.0784 - val_acc: 0.9754\n",
      "Epoch 54/150\n",
      "26880/26880 [==============================] - 20s 747us/step - loss: 0.0917 - acc: 0.9711 - val_loss: 0.0785 - val_acc: 0.9753\n",
      "Epoch 55/150\n",
      "26880/26880 [==============================] - 18s 668us/step - loss: 0.0948 - acc: 0.9706 - val_loss: 0.0774 - val_acc: 0.9757\n",
      "Epoch 56/150\n",
      "26880/26880 [==============================] - 16s 613us/step - loss: 0.0914 - acc: 0.9709 - val_loss: 0.0761 - val_acc: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "26880/26880 [==============================] - 18s 683us/step - loss: 0.0893 - acc: 0.9711 - val_loss: 0.0759 - val_acc: 0.9762\n",
      "Epoch 58/150\n",
      "26880/26880 [==============================] - 17s 639us/step - loss: 0.0864 - acc: 0.9735 - val_loss: 0.0749 - val_acc: 0.9771\n",
      "Epoch 59/150\n",
      "26880/26880 [==============================] - 17s 639us/step - loss: 0.0885 - acc: 0.9726 - val_loss: 0.0751 - val_acc: 0.9769\n",
      "Epoch 60/150\n",
      "26880/26880 [==============================] - 16s 592us/step - loss: 0.0868 - acc: 0.9727 - val_loss: 0.0745 - val_acc: 0.9769\n",
      "Epoch 61/150\n",
      "26880/26880 [==============================] - 17s 625us/step - loss: 0.0881 - acc: 0.9721 - val_loss: 0.0733 - val_acc: 0.9781\n",
      "Epoch 62/150\n",
      "26880/26880 [==============================] - 17s 637us/step - loss: 0.0846 - acc: 0.9733 - val_loss: 0.0713 - val_acc: 0.9774\n",
      "Epoch 63/150\n",
      "26880/26880 [==============================] - 15s 560us/step - loss: 0.0849 - acc: 0.9732 - val_loss: 0.0712 - val_acc: 0.9781\n",
      "Epoch 64/150\n",
      "26880/26880 [==============================] - 15s 571us/step - loss: 0.0823 - acc: 0.9749 - val_loss: 0.0709 - val_acc: 0.9783\n",
      "Epoch 65/150\n",
      "26880/26880 [==============================] - 16s 599us/step - loss: 0.0817 - acc: 0.9744 - val_loss: 0.0707 - val_acc: 0.9778\n",
      "Epoch 66/150\n",
      "26880/26880 [==============================] - 17s 614us/step - loss: 0.0802 - acc: 0.9745 - val_loss: 0.0700 - val_acc: 0.9780\n",
      "Epoch 67/150\n",
      "26880/26880 [==============================] - 16s 580us/step - loss: 0.0798 - acc: 0.9740 - val_loss: 0.0698 - val_acc: 0.9789\n",
      "Epoch 68/150\n",
      "26880/26880 [==============================] - 16s 581us/step - loss: 0.0792 - acc: 0.9753 - val_loss: 0.0690 - val_acc: 0.9783\n",
      "Epoch 69/150\n",
      "26880/26880 [==============================] - 16s 585us/step - loss: 0.0799 - acc: 0.9755 - val_loss: 0.0676 - val_acc: 0.9792\n",
      "Epoch 70/150\n",
      "26880/26880 [==============================] - 18s 687us/step - loss: 0.0773 - acc: 0.9748 - val_loss: 0.0675 - val_acc: 0.9795\n",
      "Epoch 71/150\n",
      "26880/26880 [==============================] - 17s 631us/step - loss: 0.0763 - acc: 0.9760 - val_loss: 0.0673 - val_acc: 0.9783\n",
      "Epoch 72/150\n",
      "26880/26880 [==============================] - 17s 617us/step - loss: 0.0773 - acc: 0.9746 - val_loss: 0.0663 - val_acc: 0.9786\n",
      "Epoch 73/150\n",
      "26880/26880 [==============================] - 17s 616us/step - loss: 0.0763 - acc: 0.9758 - val_loss: 0.0659 - val_acc: 0.9789\n",
      "Epoch 74/150\n",
      "26880/26880 [==============================] - 16s 588us/step - loss: 0.0762 - acc: 0.9754 - val_loss: 0.0649 - val_acc: 0.9795\n",
      "Epoch 75/150\n",
      "26880/26880 [==============================] - 16s 587us/step - loss: 0.0765 - acc: 0.9760 - val_loss: 0.0649 - val_acc: 0.9805\n",
      "Epoch 76/150\n",
      "26880/26880 [==============================] - 16s 592us/step - loss: 0.0764 - acc: 0.9758 - val_loss: 0.0645 - val_acc: 0.9793\n",
      "Epoch 77/150\n",
      "26880/26880 [==============================] - 17s 650us/step - loss: 0.0726 - acc: 0.9778 - val_loss: 0.0649 - val_acc: 0.9801\n",
      "Epoch 78/150\n",
      "26880/26880 [==============================] - 19s 697us/step - loss: 0.0740 - acc: 0.9773 - val_loss: 0.0643 - val_acc: 0.9810\n",
      "Epoch 79/150\n",
      "26880/26880 [==============================] - 17s 624us/step - loss: 0.0734 - acc: 0.9761 - val_loss: 0.0626 - val_acc: 0.9807\n",
      "Epoch 80/150\n",
      "26880/26880 [==============================] - 16s 610us/step - loss: 0.0728 - acc: 0.9765 - val_loss: 0.0620 - val_acc: 0.9810\n",
      "Epoch 81/150\n",
      "26880/26880 [==============================] - 19s 695us/step - loss: 0.0701 - acc: 0.9785 - val_loss: 0.0626 - val_acc: 0.9804\n",
      "Epoch 82/150\n",
      "26880/26880 [==============================] - 16s 597us/step - loss: 0.0688 - acc: 0.9782 - val_loss: 0.0621 - val_acc: 0.9805\n",
      "Epoch 83/150\n",
      "26880/26880 [==============================] - 16s 606us/step - loss: 0.0693 - acc: 0.9772 - val_loss: 0.0611 - val_acc: 0.9815\n",
      "Epoch 84/150\n",
      "26880/26880 [==============================] - 16s 585us/step - loss: 0.0699 - acc: 0.9780 - val_loss: 0.0614 - val_acc: 0.9814\n",
      "Epoch 85/150\n",
      "26880/26880 [==============================] - 16s 583us/step - loss: 0.0693 - acc: 0.9778 - val_loss: 0.0610 - val_acc: 0.9810\n",
      "Epoch 86/150\n",
      "26880/26880 [==============================] - 16s 600us/step - loss: 0.0694 - acc: 0.9780 - val_loss: 0.0610 - val_acc: 0.9811\n",
      "Epoch 87/150\n",
      "26880/26880 [==============================] - 16s 611us/step - loss: 0.0653 - acc: 0.9790 - val_loss: 0.0607 - val_acc: 0.9815\n",
      "Epoch 88/150\n",
      "26880/26880 [==============================] - 18s 662us/step - loss: 0.0691 - acc: 0.9774 - val_loss: 0.0590 - val_acc: 0.9817\n",
      "Epoch 89/150\n",
      "26880/26880 [==============================] - 16s 585us/step - loss: 0.0647 - acc: 0.9794 - val_loss: 0.0595 - val_acc: 0.9827\n",
      "Epoch 90/150\n",
      "26880/26880 [==============================] - 16s 585us/step - loss: 0.0662 - acc: 0.9786 - val_loss: 0.0589 - val_acc: 0.9830\n",
      "Epoch 91/150\n",
      "26880/26880 [==============================] - 15s 571us/step - loss: 0.0647 - acc: 0.9795 - val_loss: 0.0594 - val_acc: 0.9821\n",
      "Epoch 92/150\n",
      "26880/26880 [==============================] - 16s 592us/step - loss: 0.0656 - acc: 0.9797 - val_loss: 0.0584 - val_acc: 0.9817\n",
      "Epoch 93/150\n",
      "26880/26880 [==============================] - 17s 635us/step - loss: 0.0622 - acc: 0.9802 - val_loss: 0.0591 - val_acc: 0.9820\n",
      "Epoch 94/150\n",
      "26880/26880 [==============================] - 16s 608us/step - loss: 0.0651 - acc: 0.9786 - val_loss: 0.0575 - val_acc: 0.9830\n",
      "Epoch 95/150\n",
      "26880/26880 [==============================] - 17s 641us/step - loss: 0.0620 - acc: 0.9801 - val_loss: 0.0572 - val_acc: 0.9826\n",
      "Epoch 96/150\n",
      "26880/26880 [==============================] - 16s 600us/step - loss: 0.0639 - acc: 0.9797 - val_loss: 0.0572 - val_acc: 0.9832\n",
      "Epoch 97/150\n",
      "26880/26880 [==============================] - 16s 610us/step - loss: 0.0626 - acc: 0.9804 - val_loss: 0.0574 - val_acc: 0.9818\n",
      "Epoch 98/150\n",
      "26880/26880 [==============================] - 17s 617us/step - loss: 0.0611 - acc: 0.9799 - val_loss: 0.0556 - val_acc: 0.9830\n",
      "Epoch 99/150\n",
      "26880/26880 [==============================] - 17s 622us/step - loss: 0.0616 - acc: 0.9805 - val_loss: 0.0560 - val_acc: 0.9824\n",
      "Epoch 100/150\n",
      "26880/26880 [==============================] - 16s 612us/step - loss: 0.0607 - acc: 0.9802 - val_loss: 0.0560 - val_acc: 0.9835\n",
      "Epoch 101/150\n",
      "26880/26880 [==============================] - 17s 621us/step - loss: 0.0604 - acc: 0.9810 - val_loss: 0.0552 - val_acc: 0.9836\n",
      "Epoch 102/150\n",
      "26880/26880 [==============================] - 16s 611us/step - loss: 0.0604 - acc: 0.9810 - val_loss: 0.0552 - val_acc: 0.9833\n",
      "Epoch 103/150\n",
      "26880/26880 [==============================] - 17s 627us/step - loss: 0.0602 - acc: 0.9811 - val_loss: 0.0558 - val_acc: 0.9838\n",
      "Epoch 104/150\n",
      "26880/26880 [==============================] - 16s 591us/step - loss: 0.0579 - acc: 0.9823 - val_loss: 0.0550 - val_acc: 0.9835\n",
      "Epoch 105/150\n",
      "26880/26880 [==============================] - 17s 640us/step - loss: 0.0584 - acc: 0.9814 - val_loss: 0.0549 - val_acc: 0.9835\n",
      "Epoch 106/150\n",
      "26880/26880 [==============================] - 16s 606us/step - loss: 0.0583 - acc: 0.9811 - val_loss: 0.0548 - val_acc: 0.9841\n",
      "Epoch 107/150\n",
      "26880/26880 [==============================] - 17s 628us/step - loss: 0.0571 - acc: 0.9820 - val_loss: 0.0557 - val_acc: 0.9841\n",
      "Epoch 108/150\n",
      "26880/26880 [==============================] - 17s 627us/step - loss: 0.0589 - acc: 0.9811 - val_loss: 0.0542 - val_acc: 0.9842\n",
      "Epoch 109/150\n",
      "26880/26880 [==============================] - 18s 677us/step - loss: 0.0563 - acc: 0.9818 - val_loss: 0.0543 - val_acc: 0.9835\n",
      "Epoch 110/150\n",
      "26880/26880 [==============================] - 17s 631us/step - loss: 0.0570 - acc: 0.9817 - val_loss: 0.0536 - val_acc: 0.9845\n",
      "Epoch 111/150\n",
      "26880/26880 [==============================] - 17s 628us/step - loss: 0.0570 - acc: 0.9809 - val_loss: 0.0540 - val_acc: 0.9844\n",
      "Epoch 112/150\n",
      "26880/26880 [==============================] - 16s 600us/step - loss: 0.0566 - acc: 0.9814 - val_loss: 0.0536 - val_acc: 0.9839\n",
      "Epoch 113/150\n",
      "26880/26880 [==============================] - 17s 617us/step - loss: 0.0555 - acc: 0.9820 - val_loss: 0.0533 - val_acc: 0.9842\n",
      "Epoch 114/150\n",
      "26880/26880 [==============================] - 17s 624us/step - loss: 0.0557 - acc: 0.9820 - val_loss: 0.0527 - val_acc: 0.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "26880/26880 [==============================] - 16s 604us/step - loss: 0.0576 - acc: 0.9810 - val_loss: 0.0525 - val_acc: 0.9838\n",
      "Epoch 116/150\n",
      "26880/26880 [==============================] - 17s 640us/step - loss: 0.0560 - acc: 0.9820 - val_loss: 0.0524 - val_acc: 0.9841\n",
      "Epoch 117/150\n",
      "26880/26880 [==============================] - 16s 610us/step - loss: 0.0561 - acc: 0.9822 - val_loss: 0.0518 - val_acc: 0.9842\n",
      "Epoch 118/150\n",
      "26880/26880 [==============================] - 18s 665us/step - loss: 0.0550 - acc: 0.9818 - val_loss: 0.0521 - val_acc: 0.9842\n",
      "Epoch 119/150\n",
      "26880/26880 [==============================] - 17s 617us/step - loss: 0.0537 - acc: 0.9828 - val_loss: 0.0512 - val_acc: 0.9847\n",
      "Epoch 120/150\n",
      "26880/26880 [==============================] - 16s 598us/step - loss: 0.0551 - acc: 0.9822 - val_loss: 0.0510 - val_acc: 0.9842\n",
      "Epoch 121/150\n",
      "26880/26880 [==============================] - 17s 624us/step - loss: 0.0541 - acc: 0.9824 - val_loss: 0.0513 - val_acc: 0.9848\n",
      "Epoch 122/150\n",
      "26880/26880 [==============================] - 16s 578us/step - loss: 0.0523 - acc: 0.9837 - val_loss: 0.0521 - val_acc: 0.9841\n",
      "Epoch 123/150\n",
      "26880/26880 [==============================] - 15s 558us/step - loss: 0.0538 - acc: 0.9825 - val_loss: 0.0505 - val_acc: 0.9851\n",
      "Epoch 124/150\n",
      "26880/26880 [==============================] - 17s 616us/step - loss: 0.0524 - acc: 0.9827 - val_loss: 0.0505 - val_acc: 0.9853\n",
      "Epoch 125/150\n",
      "26880/26880 [==============================] - 18s 668us/step - loss: 0.0522 - acc: 0.9835 - val_loss: 0.0508 - val_acc: 0.9853\n",
      "Epoch 126/150\n",
      "26880/26880 [==============================] - 18s 673us/step - loss: 0.0518 - acc: 0.9842 - val_loss: 0.0506 - val_acc: 0.9850\n",
      "Epoch 127/150\n",
      "26880/26880 [==============================] - 17s 619us/step - loss: 0.0529 - acc: 0.9829 - val_loss: 0.0512 - val_acc: 0.9847\n",
      "Epoch 128/150\n",
      "26880/26880 [==============================] - 16s 596us/step - loss: 0.0521 - acc: 0.9830 - val_loss: 0.0503 - val_acc: 0.9847\n",
      "Epoch 129/150\n",
      "26880/26880 [==============================] - 17s 642us/step - loss: 0.0496 - acc: 0.9838 - val_loss: 0.0494 - val_acc: 0.9853\n",
      "Epoch 130/150\n",
      "26880/26880 [==============================] - 18s 654us/step - loss: 0.0518 - acc: 0.9826 - val_loss: 0.0500 - val_acc: 0.9853\n",
      "Epoch 131/150\n",
      "26880/26880 [==============================] - 17s 630us/step - loss: 0.0494 - acc: 0.9839 - val_loss: 0.0496 - val_acc: 0.9850\n",
      "Epoch 132/150\n",
      "26880/26880 [==============================] - 16s 585us/step - loss: 0.0488 - acc: 0.9842 - val_loss: 0.0511 - val_acc: 0.9844\n",
      "Epoch 133/150\n",
      "26880/26880 [==============================] - 19s 699us/step - loss: 0.0502 - acc: 0.9840 - val_loss: 0.0499 - val_acc: 0.9847\n",
      "Epoch 134/150\n",
      "26880/26880 [==============================] - 18s 669us/step - loss: 0.0500 - acc: 0.9837 - val_loss: 0.0486 - val_acc: 0.9857\n",
      "Epoch 135/150\n",
      "26880/26880 [==============================] - 16s 610us/step - loss: 0.0484 - acc: 0.9840 - val_loss: 0.0488 - val_acc: 0.9857\n",
      "Epoch 136/150\n",
      "26880/26880 [==============================] - 17s 639us/step - loss: 0.0489 - acc: 0.9836 - val_loss: 0.0482 - val_acc: 0.9851\n",
      "Epoch 137/150\n",
      "26880/26880 [==============================] - 17s 621us/step - loss: 0.0484 - acc: 0.9840 - val_loss: 0.0487 - val_acc: 0.9859\n",
      "Epoch 138/150\n",
      "26880/26880 [==============================] - 16s 601us/step - loss: 0.0470 - acc: 0.9849 - val_loss: 0.0489 - val_acc: 0.9862\n",
      "Epoch 139/150\n",
      "26880/26880 [==============================] - 16s 611us/step - loss: 0.0487 - acc: 0.9846 - val_loss: 0.0485 - val_acc: 0.9854\n",
      "Epoch 140/150\n",
      "26880/26880 [==============================] - 16s 613us/step - loss: 0.0470 - acc: 0.9850 - val_loss: 0.0481 - val_acc: 0.9851\n",
      "Epoch 141/150\n",
      "26880/26880 [==============================] - 16s 581us/step - loss: 0.0465 - acc: 0.9853 - val_loss: 0.0475 - val_acc: 0.9859\n",
      "Epoch 142/150\n",
      "26880/26880 [==============================] - 15s 574us/step - loss: 0.0466 - acc: 0.9858 - val_loss: 0.0472 - val_acc: 0.9862\n",
      "Epoch 143/150\n",
      "26880/26880 [==============================] - 18s 665us/step - loss: 0.0477 - acc: 0.9847 - val_loss: 0.0477 - val_acc: 0.9859\n",
      "Epoch 144/150\n",
      "26880/26880 [==============================] - 17s 623us/step - loss: 0.0472 - acc: 0.9846 - val_loss: 0.0478 - val_acc: 0.9859\n",
      "Epoch 145/150\n",
      "26880/26880 [==============================] - 17s 631us/step - loss: 0.0465 - acc: 0.9852 - val_loss: 0.0472 - val_acc: 0.9856\n",
      "Epoch 146/150\n",
      "26880/26880 [==============================] - 16s 581us/step - loss: 0.0482 - acc: 0.9842 - val_loss: 0.0472 - val_acc: 0.9865\n",
      "Epoch 147/150\n",
      "26880/26880 [==============================] - 15s 572us/step - loss: 0.0458 - acc: 0.9857 - val_loss: 0.0474 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 148/150\n",
      "26880/26880 [==============================] - 19s 694us/step - loss: 0.0462 - acc: 0.9840 - val_loss: 0.0470 - val_acc: 0.9865\n",
      "Epoch 149/150\n",
      "26880/26880 [==============================] - 18s 663us/step - loss: 0.0446 - acc: 0.9861 - val_loss: 0.0467 - val_acc: 0.9863\n",
      "Epoch 150/150\n",
      "26880/26880 [==============================] - 17s 621us/step - loss: 0.0455 - acc: 0.9861 - val_loss: 0.0467 - val_acc: 0.9865\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train, batch_size = batch_size, epochs = nb_epoch, verbose = 1, validation_split = 0.2, shuffle = True, callbacks = [ReducedLR, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f082c36128>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss'] \n",
    "train_acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(hist.history[\"val_loss\"]), np.min(hist.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.05272779184038795 Accuracy: 0.9845238095238096\n"
     ]
    }
   ],
   "source": [
    "# Find test loss and accuracy\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) # accuracy check\n",
    "print('Test loss:', score[0], 'Accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "test_data = np.genfromtxt('test.csv', delimiter = ',')\n",
    "test_data = test_data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.reshape(test_data.shape[0], img_rows, img_cols, 1) \n",
    "test_data = test_data.astype('float32')\n",
    "\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 ... 3 9 2]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(test_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"Label\": predictions})\n",
    "output.to_csv(\"submission.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
